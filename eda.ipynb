{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded.\n",
      "Shape: (30706, 12)\n",
      "\n",
      "Columns: ['Topic', 'Explanation', 'Question', 'Answer', 'Difficulty', 'StudentLevel', 'QuestionType', 'QuestionComplexity', 'Prerequisites', 'EstimatedTime', 'subject', 'grade']\n",
      "\n",
      "=== Missing Values ===\n",
      "Topic                 0\n",
      "Explanation           0\n",
      "Question              0\n",
      "Answer                0\n",
      "Difficulty            0\n",
      "StudentLevel          0\n",
      "QuestionType          0\n",
      "QuestionComplexity    0\n",
      "Prerequisites         0\n",
      "EstimatedTime         0\n",
      "subject               0\n",
      "grade                 0\n",
      "dtype: int64\n",
      "\n",
      "=== Length Statistics ===\n",
      "       len_Explanation  len_Question    len_Answer\n",
      "count     30706.000000  30706.000000  30706.000000\n",
      "mean         77.934899     14.077118     32.179997\n",
      "std          23.010455      5.206792     19.562341\n",
      "min           1.000000      1.000000      1.000000\n",
      "25%          63.000000     11.000000     16.000000\n",
      "50%          74.000000     14.000000     32.000000\n",
      "75%          87.000000     17.000000     45.000000\n",
      "max         308.000000     81.000000    177.000000\n",
      "\n",
      "=== Duplicates ===\n",
      "Duplicate Questions: 2429\n",
      "Duplicate Question+Answer pairs: 1008\n",
      "Duplicate Answers: 1677\n",
      "\n",
      "Top 20 most repeated Answers:\n",
      "Answer\n",
      "Refraction                                                                                                                  23\n",
      "James Clerk Maxwell                                                                                                         16\n",
      "Biodiversity                                                                                                                15\n",
      "Niels Bohr                                                                                                                  12\n",
      "Michael Faraday                                                                                                             12\n",
      "Photosynthesis                                                                                                              11\n",
      "Gregor Mendel                                                                                                               11\n",
      "Electromagnetic Induction                                                                                                   10\n",
      "AC stands for Alternating Current.                                                                                          10\n",
      "Pollination                                                                                                                 10\n",
      "Natural selection                                                                                                           10\n",
      "Chemical equilibrium                                                                                                        10\n",
      "The photoelectric effect.                                                                                                    9\n",
      "Oxygen                                                                                                                       9\n",
      "The formula for Newton's Second Law of Motion is F = ma, where F is the force, m is the mass, and a is the acceleration.     9\n",
      "John Dalton                                                                                                                  8\n",
      "SHM stands for Simple Harmonic Motion.                                                                                       8\n",
      "Dmitri Mendeleev                                                                                                             8\n",
      "ATP (adenosine triphosphate)                                                                                                 8\n",
      "Osmosis                                                                                                                      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Subject Distribution (raw) ===\n",
      "subject\n",
      "Physics      10505\n",
      "Chemistry     9911\n",
      "Biology       6894\n",
      "Science       3396\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Grade Distribution ===\n",
      "grade\n",
      "11    14533\n",
      "12    12777\n",
      "10     3396\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Difficulty Distribution ===\n",
      "Difficulty\n",
      "Medium        10267\n",
      "Hard          10242\n",
      "Easy          10193\n",
      "Difficulty        4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Student Level Distribution ===\n",
      "StudentLevel\n",
      "Intermediate    10267\n",
      "Advanced        10242\n",
      "Beginner        10193\n",
      "StudentLevel        4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Question Type ===\n",
      "QuestionType\n",
      "General         16636\n",
      "Conceptual      13109\n",
      "Numerical         714\n",
      "Proof             144\n",
      "Analytical         99\n",
      "QuestionType        4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Question Complexity ===\n",
      "QuestionComplexity\n",
      "0.300000    1277\n",
      "0.325000    1227\n",
      "0.275000    1210\n",
      "0.250000    1163\n",
      "0.350000    1132\n",
      "            ... \n",
      "0.845968       1\n",
      "0.842969       1\n",
      "0.844355       1\n",
      "0.863281       1\n",
      "0.724107       1\n",
      "Name: count, Length: 755, dtype: int64\n",
      "\n",
      "=== Outlier Explanations ===\n",
      "Very Long (Top 1%): 307\n",
      "Very Short (Bottom 1%): 257\n",
      "\n",
      "=== EDA Completed ===\n",
      "Reports saved to: eda_reports\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------\n",
    "# Paths\n",
    "# ---------------------------------\n",
    "CSV_PATH = \"class_10_11_12.csv\"\n",
    "OUT_DIR = Path(\"eda_reports\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------------------------------\n",
    "# Load dataset\n",
    "# ---------------------------------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Dataset Loaded.\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "# ---------------------------------\n",
    "# 1. Missing values summary\n",
    "# ---------------------------------\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(missing)\n",
    "\n",
    "missing.to_csv(OUT_DIR / \"missing_values.csv\")\n",
    "\n",
    "# ---------------------------------\n",
    "# 2. Basic stats on text lengths\n",
    "# ---------------------------------\n",
    "def text_len(s):\n",
    "    if isinstance(s, str):\n",
    "        return len(s.split())\n",
    "    return 0\n",
    "\n",
    "df[\"len_Explanation\"] = df[\"Explanation\"].apply(text_len)\n",
    "df[\"len_Question\"] = df[\"Question\"].apply(text_len)\n",
    "df[\"len_Answer\"] = df[\"Answer\"].apply(text_len)\n",
    "\n",
    "length_stats = df[[\"len_Explanation\",\"len_Question\",\"len_Answer\"]].describe()\n",
    "print(\"\\n=== Length Statistics ===\")\n",
    "print(length_stats)\n",
    "\n",
    "length_stats.to_csv(OUT_DIR / \"length_stats.csv\")\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df[\"len_Explanation\"], bins=50, kde=True)\n",
    "plt.title(\"Explanation Length Distribution (words)\")\n",
    "plt.savefig(OUT_DIR / \"explanation_length_dist.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df[\"len_Question\"], bins=50, kde=True)\n",
    "plt.title(\"Question Length Distribution (words)\")\n",
    "plt.savefig(OUT_DIR / \"question_length_dist.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df[\"len_Answer\"], bins=50, kde=True)\n",
    "plt.title(\"Answer Length Distribution (words)\")\n",
    "plt.savefig(OUT_DIR / \"answer_length_dist.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------\n",
    "# 3. Duplicate checks\n",
    "# ---------------------------------\n",
    "dupe_q = df.duplicated(subset=[\"Question\"]).sum()\n",
    "dupe_qa = df.duplicated(subset=[\"Question\",\"Answer\"]).sum()\n",
    "\n",
    "print(\"\\n=== Duplicates ===\")\n",
    "print(\"Duplicate Questions:\", dupe_q)\n",
    "print(\"Duplicate Question+Answer pairs:\", dupe_qa)\n",
    "\n",
    "# Save duplicates data\n",
    "df[df.duplicated(subset=[\"Question\"], keep=False)].to_csv(\n",
    "    OUT_DIR / \"duplicate_questions.csv\", index=False)\n",
    "\n",
    "df[df.duplicated(subset=[\"Question\",\"Answer\"], keep=False)].to_csv(\n",
    "    OUT_DIR / \"duplicate_QA.csv\", index=False)\n",
    "\n",
    "# --- NEW: Duplicate Answers ---\n",
    "dupe_a = df.duplicated(subset=[\"Answer\"]).sum()\n",
    "print(\"Duplicate Answers:\", dupe_a)\n",
    "\n",
    "df[df.duplicated(subset=[\"Answer\"], keep=False)].to_csv(\n",
    "    OUT_DIR / \"duplicate_answers.csv\", index=False\n",
    ")\n",
    "\n",
    "# Extra: frequency of each answer (to know which answers repeat how many times)\n",
    "answer_counts = df[\"Answer\"].value_counts()\n",
    "answer_counts.to_csv(OUT_DIR / \"answer_duplicate_counts.csv\")\n",
    "\n",
    "print(\"\\nTop 20 most repeated Answers:\")\n",
    "print(answer_counts.head(20))\n",
    "\n",
    "# ---------------------------------\n",
    "# 4. Subject distribution (raw)\n",
    "# ---------------------------------\n",
    "if \"subject\" in df.columns:\n",
    "    subj_counts = df[\"subject\"].value_counts()\n",
    "    print(\"\\n=== Subject Distribution (raw) ===\")\n",
    "    print(subj_counts)\n",
    "    subj_counts.to_csv(OUT_DIR / \"subject_distribution.csv\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(x=subj_counts.index, y=subj_counts.values)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Subject Distribution\")\n",
    "    plt.savefig(OUT_DIR / \"subject_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------------\n",
    "# 5. Grade distribution\n",
    "# ---------------------------------\n",
    "if \"grade\" in df.columns:\n",
    "    grade_counts = df[\"grade\"].value_counts()\n",
    "    print(\"\\n=== Grade Distribution ===\")\n",
    "    print(grade_counts)\n",
    "    grade_counts.to_csv(OUT_DIR / \"grade_distribution.csv\")\n",
    "\n",
    "# ---------------------------------\n",
    "# 6. Difficulty distribution\n",
    "# ---------------------------------\n",
    "if \"Difficulty\" in df.columns:\n",
    "    diff_counts = df[\"Difficulty\"].value_counts()\n",
    "    print(\"\\n=== Difficulty Distribution ===\")\n",
    "    print(diff_counts)\n",
    "    diff_counts.to_csv(OUT_DIR / \"difficulty_distribution.csv\")\n",
    "\n",
    "# ---------------------------------\n",
    "# 7. StudentLevel distribution\n",
    "# ---------------------------------\n",
    "if \"StudentLevel\" in df.columns:\n",
    "    stu_counts = df[\"StudentLevel\"].value_counts()\n",
    "    print(\"\\n=== Student Level Distribution ===\")\n",
    "    print(stu_counts)\n",
    "    stu_counts.to_csv(OUT_DIR / \"student_level_distribution.csv\")\n",
    "\n",
    "# ---------------------------------\n",
    "# 8. QuestionType / QuestionComplexity distribution\n",
    "# ---------------------------------\n",
    "if \"QuestionType\" in df.columns:\n",
    "    qt_counts = df[\"QuestionType\"].value_counts()\n",
    "    print(\"\\n=== Question Type ===\")\n",
    "    print(qt_counts)\n",
    "    qt_counts.to_csv(OUT_DIR / \"question_type_distribution.csv\")\n",
    "\n",
    "if \"QuestionComplexity\" in df.columns:\n",
    "    qc_counts = df[\"QuestionComplexity\"].value_counts()\n",
    "    print(\"\\n=== Question Complexity ===\")\n",
    "    print(qc_counts)\n",
    "    qc_counts.to_csv(OUT_DIR / \"question_complexity_distribution.csv\")\n",
    "\n",
    "# ---------------------------------\n",
    "# 9. Explanation Outliers (too long / too short)\n",
    "# ---------------------------------\n",
    "exp_lengths = df[\"len_Explanation\"]\n",
    "long_outliers = df[exp_lengths > exp_lengths.quantile(0.99)]\n",
    "short_outliers = df[exp_lengths < exp_lengths.quantile(0.01)]\n",
    "\n",
    "print(\"\\n=== Outlier Explanations ===\")\n",
    "print(\"Very Long (Top 1%):\", len(long_outliers))\n",
    "print(\"Very Short (Bottom 1%):\", len(short_outliers))\n",
    "\n",
    "long_outliers.to_csv(OUT_DIR / \"long_explanations.csv\")\n",
    "short_outliers.to_csv(OUT_DIR / \"short_explanations.csv\")\n",
    "\n",
    "# ---------------------------------\n",
    "# Final summary\n",
    "# ---------------------------------\n",
    "print(\"\\n=== EDA Completed ===\")\n",
    "print(\"Reports saved to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/purushottam/miniconda3/envs/qg_lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    30706.000000\n",
      "mean       117.108904\n",
      "std         40.394809\n",
      "min          4.000000\n",
      "25%         90.000000\n",
      "50%        109.000000\n",
      "75%        134.000000\n",
      "90%        167.000000\n",
      "95%        194.000000\n",
      "98%        232.000000\n",
      "99%        258.950000\n",
      "max        502.000000\n",
      "Name: expl_tok_len, dtype: float64\n",
      "256 tokens covers 98.95% of Explanations\n",
      "320 tokens covers 99.79% of Explanations\n",
      "384 tokens covers 99.97% of Explanations\n",
      "512 tokens covers 100.00% of Explanations\n",
      "98% cutoff (tokens): 232\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_PATH = \"class_10_11_12.csv\"\n",
    "MODEL = \"t5-base\"   # change to your model/tokenizer\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "\n",
    "# function to get token length of the Explanation (or full prompt)\n",
    "def tok_len(text):\n",
    "    return len(tokenizer.encode(text, truncation=False))\n",
    "\n",
    "# measure Explanation token lengths for a sample or all rows\n",
    "df[\"expl_tok_len\"] = df[\"Explanation\"].fillna(\"\").astype(str).map(lambda t: tok_len(t))\n",
    "\n",
    "# stats\n",
    "print(df[\"expl_tok_len\"].describe(percentiles=[.25, .5, .75, .9, .95, .98, .99]))\n",
    "\n",
    "# get what percentage would fit within X tokens\n",
    "for cutoff in [256, 320, 384, 512]:\n",
    "    pct = (df[\"expl_tok_len\"] <= cutoff).mean() * 100\n",
    "    print(f\"{cutoff} tokens covers {pct:.2f}% of Explanations\")\n",
    "\n",
    "# Example: to choose cutoff covering 98%:\n",
    "target_pct = 0.98\n",
    "cutoff_token = int(np.quantile(df[\"expl_tok_len\"], target_pct))\n",
    "print(\"98% cutoff (tokens):\", cutoff_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qg_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
